# üó∫Ô∏è ROADMAP ‚Äî Real-Time Monocular Depth Enhancement for AR Occlusion
**Team:** Alone  
**Member:** Artyom Tsay (ID: 220748)  
**Course:** Computer Vision ‚Äì Fall 2025  
**Supervisors:** Dr. I. Atadjanov & Dr. B. Kiani  
**Repo:** [xts-art/Real-time-monocular-depth-enhancement-for-AR-occlusion](https://github.com/xts-art/Real-time-monocular-depth-enhancement-for-AR-occlusion)

---

## üìç Scope
This project develops a **real-time monocular depth enhancement** system for **AR occlusion** in mixed reality headsets.  
It fine-tunes lightweight monocular depth models (MiDaS / Depth Anything) with **temporal smoothing** and **self-supervised adaptation**,  
aiming for temporally stable, spatially accurate, and efficient depth estimation suitable for **mobile or embedded AR GPUs**.

**Key Metrics:**  
- RMSE, AbsRel (accuracy)  
- SSIM (structural similarity)  
- Temporal Flicker Index (stability)  
- Latency (end-to-end <50 ms)  

---

## üóìÔ∏è Milestones (Tashkent time)

### **W1 ¬∑ Oct 27 ‚Äì Nov 2**
Repository setup, baseline MiDaS/Depth-Anything integration, CI structure, initial dataset preparation.  
**Owner:** Artyom Tsay  
**Deliverable:** Repo initialized with working baseline.  
**Status:** üü© Planned

---

### **W2 ¬∑ Nov 3 ‚Äì Nov 9**
Baseline fine-tuning on small dataset (KITTI/NYU/TUM).  
Compute baseline metrics (RMSE, AbsRel, SSIM).  
**Owner:** Artyom Tsay  
**Deliverable:** Baseline model trained and benchmarked.  
**Status:** üü© Planned

---

### **W3 ¬∑ Nov 10 ‚Äì Nov 16**
Add temporal smoothing layer (optical-flow or recurrent filtering).  
Evaluate stability improvements (Temporal Flicker Index).  
**Owner:** Artyom Tsay  
**Deliverable:** Temporally stabilized model v1.  
**Status:** üü© Planned

---

### **W4 ¬∑ Nov 17 ‚Äì Nov 23**
Implement self-supervised pseudo-stereo fine-tuning.  
Train on synthetic-to-real blended dataset (Blender / Unity).  
**Owner:** Artyom Tsay  
**Deliverable:** Self-adaptive model v2 with improved temporal consistency.  
**Status:** üü© Planned

---

### **W5 ¬∑ Nov 24 ‚Äì Nov 30**
Quantize and export model to **ONNX Runtime** for mobile inference.  
Latency profiling on RTX 3060 (local) and Colab (T4).  
**Owner:** Artyom Tsay  
**Deliverable:** Real-time model (latency <50 ms).  
**Status:** üü© Planned

---

### **W6 ¬∑ Dec 1 ‚Äì Dec 7**
Final evaluation and visualization.  
Compare temporal and spatial quality across test videos.  
Generate demo sequence for AR occlusion.  
**Owner:** Artyom Tsay  
**Deliverable:** Evaluation report + demo video draft.  
**Status:** üü© Planned

---

### **W7 ¬∑ Dec 8 ‚Äì Dec 14**
Conduct ablation experiments:  
- With vs. without temporal smoothing  
- With vs. without self-supervised tuning  
Analyze trade-offs in latency and quality.  
**Owner:** Artyom Tsay  
**Deliverable:** Ablation summary table + plots.  
**Status:** üü© Planned

---

### **W8 ¬∑ Dec 15 ‚Äì Dec 21**
Prepare final report (PDF), README polish, and GitHub release.  
Include side-by-side comparison visuals and code documentation.  
**Owner:** Artyom Tsay  
**Deliverable:** Final paper-ready report.  
**Status:** üü© Planned

---

### **W9 ¬∑ Dec 22 ‚Äì Dec 27**
Final demo recording, repository cleanup, and presentation slides.  
Submit final version for grading (midterm + final).  
**Owner:** Artyom Tsay  
**Deliverable:** Demo video, slides, and GitHub repo submission.  
**Status:** üü© Planned

---

## üß© RACI Matrix

| Task | Responsible | Accountable | Consulted | Informed |
|------|--------------|-------------|------------|-----------|
| Baseline model setup | Artyom Tsay | Artyom Tsay | ‚Äî | Instructor, TA |
| Temporal smoothing integration | Artyom Tsay | Artyom Tsay | ‚Äî | Instructor |
| Self-supervised tuning | Artyom Tsay | Artyom Tsay | ‚Äî | Instructor |
| ONNX optimization | Artyom Tsay | Artyom Tsay | ‚Äî | Instructor |
| Evaluation & demo | Artyom Tsay | Artyom Tsay | ‚Äî | Instructor |
| Report & documentation | Artyom Tsay | Artyom Tsay | ‚Äî | Instructor |

---

## üßÆ Success Criteria
- **‚â•10% RMSE improvement** vs baseline  
- **<50 ms** per-frame latency  
- **SSIM ‚â• 0.90**  
- **Reduced temporal flicker (‚â•20% stability gain)**  
- Visually smoother occlusion boundaries in demo video  

---

## ‚ö†Ô∏è Risks and Mitigations

| Risk | Mitigation |
|------|-------------|
| Limited GPU resources | Use LoRA fine-tuning and reduced model variants |
| Temporal instability under motion | Optical flow correction or EMA smoothing |
| Domain mismatch between synthetic and real data | Synthetic-to-real adaptation, pseudo-stereo tuning |
| Latency exceeding real-time threshold | Quantization and ONNX optimization |
| Insufficient visual improvement | Combine perceptual loss and temporal loss terms |

---

## üîÅ Weekly Check-ins
- Update this file weekly with 3‚Äì5 key progress notes.  
- Link commits or issues to specific milestones.  
- Include screenshots or metric tables where relevant.  

---

## üì¶ Deliverables
- Full reproducible code (training, inference, ONNX export).  
- Enhanced monocular depth model for AR occlusion.  
- Evaluation report with metrics and visual results.  
- Demo video showing improved occlusion quality.  
- (Stretch goals) Unity integration for real-time headset visualization.

---

## üîó Links
- **Proposal Document (PDF):** `CV25_Proposal_Alone.pdf`  
- **Maintained ROADMAP.md:** In project repo  
- **Weekly progress updates:** GitHub Issues + Commits  
- **Demo repo:** [xts-art/Real-time-monocular-depth-enhancement-for-AR-occlusion](https://github.com/xts-art/Real-time-monocular-depth-enhancement-for-AR-occlusion)
